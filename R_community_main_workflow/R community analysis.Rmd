--- 
title: "R community analysis"
author: "Matthew R. Gemmell"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
favicon: figures/NEOF_favicon.png
description: NEOF book for the R community analysis workflow
cover-image: "figures/NEOF.png"
---
```{r include=FALSE, cache=FALSE}
suppressPackageStartupMessages({
  library(webexercises)
})

knitr::knit_hooks$set(webex.hide = function(before, options, envir) {
  if (before) {
    if (is.character(options$webex.hide)) {
      hide(options$webex.hide)
    } else {
      hide()
    }
  } else {
    unhide()
  }
})
```

```{r cite-packages, include = FALSE}
# automatically create a bib database for R packages
# add any packages you want to cite here
knitr::write_bib(c(
  .packages(), 'bookdown', 'webexercises'
), 'packages.bib')
```

```{r, fig.align = 'center',out.width= '30%', echo=FALSE }
knitr::include_graphics(path = "figures/NEOF.png", auto_pdf = TRUE)
``` 

# Introduction
```{r, fig.align = 'center',out.width= '20%', echo=FALSE }
knitr::include_graphics(path = "figures/R_community.png", auto_pdf = TRUE)
``` 

A lot of different analysis and visualisations can be carried out with community data. This includes taxonomy and functional abundance tables from 16S rRNA and Shotgun metagenomics analysis. This workshop will teach you how to use R with the phyloseq R object; a specialised object containing an abundance, taxonomy, and metadata table. 

The workshop will use a 16S dataset that has been pre-analysed with QIIME2 to create the ASV table, taxonomy table, and phylogenetic tree. Supplementary materials will show how to import Bracken shotgun metagenomic abundance data and generic abundance data frames into a phyloseq object.
 
Sessions will start with a brief presentation followed by self-paced computer practicals guided by an online interactive book. The book will contain theory and practice code. This will be reinforced with multiple choice questions that will recap concepts and aid in interpretation of results.

At the end of the course learners will be able to:

- Import QIIME2 artifacts into a phyloseq object.
- Summarise the abundance and taxonomy contents of a phyloseq object
- Preprocess the abundance and taxonomy tables. This will include transforming sample counts, and subsetting samples & taxonomies.
- Understand the grammar of graphics (ggplot2) used by phyloseq and related packages.
- Carry out alpha & beta diversity, and biomarker detection with the phyloseq object.
- Produce and customise publication quality plots.
- Run statistical analysis and incorporate these values into the plots.
- Convert static plots into interactive html plots with plotly within R.



<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons Licence" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.

<!--chapter:end:01-R_community_main_workflow.Rmd-->

```{r include=FALSE, cache=FALSE}
suppressPackageStartupMessages({
  library(webexercises)
})

knitr::knit_hooks$set(webex.hide = function(before, options, envir) {
  if (before) {
    if (is.character(options$webex.hide)) {
      hide(options$webex.hide)
    } else {
      hide()
    }
  } else {
    unhide()
  }
})
```
# Dataset & workflow
```{r, fig.align = 'center',out.width= '15%', echo=FALSE }
knitr::include_graphics(path = "figures/data.png", auto_pdf = TRUE)
``` 

## Dataset
```{r, fig.align = 'center',out.width= '50%', echo=FALSE }
knitr::include_graphics(path = "figures/freshwater_france.png", auto_pdf = TRUE)
``` 

In this tutorial we will be using 16S metabarcdoing datasets derived from surface water from the Durance River in the south-east of France. Two major comparisons were carried out in combination with each other.

Three different sites were chosen on the Durance River. These three sites were representative of an anthropisation (transformation of land by humans) gradient along a river stream. These sites were:

- Upper Durance sampling site (UD): Bottom part of the alpine part of the river with little/no anthropisation.
- Middle Durance sampling site (MD): Upper part of agricultural land dominated by apple and pear production.
- Lower Durance sampling site (LD): Lower part of agricultural land with intensive production of fruits, cereals, and vegetables.

Surface water was sampled and different culture media were used to produce bacterial lawns for each site. The media used were:

- Environmental sample (ENV): No media used, frozen at -20°C will DNA extraction.
- TSA 10% incubated at 28°C for 2 days.
- KBC incubated at 28°C for 2 days.
- CVP incubated at 28°C for 3 days.

Each sample and media combination was produced in replicates of three giving a total of 27 samples (3*4*3 = 36). The three replicates were cultured on three different plates with the same media. An ASV table, taxonomy table, and phylogenetic tree were produced with QIIME2 and DADA2.

With this data we can ask and investigate the following questions:

- How does the bacterial communities change across the anthropisation gradient?
- Is there a difference in the replicates of one site and media combination. I.e. do any of the media produce inconsistent profiles.
- Is there more difference between the sites or the media used?
- Do any of the media produce a similar taxonomic profile to the environmental sample?


## Workflow
```{r, fig.align = 'center',out.width= '15%', echo=FALSE }
knitr::include_graphics(path = "figures/workflow.png", auto_pdf = TRUE)
```

## Scripts and working directory
```{r, fig.align = 'center',out.width= '15%', echo=FALSE }
knitr::include_graphics(path = "figures/r_script.png", auto_pdf = TRUE)
```

Different people like to sort out their workflows and directories/folders in different ways. Some people like to use [RStudio projects](https://support.posit.co/hc/en-us/articles/200526207-Using-RStudio-Projects). Personally, I like to create one directory for an analysis project. In this directory I:

- Have a directory with my input.
- I save my scripts.
- I save my output, possibly to sub-directories.

This is the method that will be used in these materials. To start, create a directory on your computer for the analysis of the French freshwater data (can be done inside our outside of RStudio. For example:

__"~/R/R_community_course/freshwater_data_analysis/"__

Next we need our data. Download and save the following link into your analysis directory:

__[freshwater_water_france.zip](https://neof-workshops.github.io/Unix_nxcdf7/01-Intro_to_Unix.html)__

It is a zipped directory, therefore unzip the directory/folder.

`r hide("Windows unzipping")`
- Open File Explorer and find the zipped folder.
- To unzip the entire folder, right-click to select Extract All, and then click "Extract".
`r unhide()`

`r hide("Mac unzipping")`
- Double-click the .zip file.
`r unhide()`

Finally, set your working directory in RStudio to your analysis directory.

<!--chapter:end:02-Dataset_and_workflow.Rmd-->

```{r include=FALSE, cache=FALSE}
suppressPackageStartupMessages({
  library(webexercises)
})

knitr::knit_hooks$set(webex.hide = function(before, options, envir) {
  if (before) {
    if (is.character(options$webex.hide)) {
      hide(options$webex.hide)
    } else {
      hide()
    }
  } else {
    unhide()
  }
})
```
# R Packages
```{r, fig.align = 'center',out.width= '20%', echo=FALSE }
knitr::include_graphics(path = "figures/R.png", auto_pdf = TRUE)
```  

During this workshop we will use various R packages with their own intricacies. Before going into analysis we'll introduce you to some of these important concepts.

## R packages/libraries
```{r, fig.align = 'center',out.width= '20%', echo=FALSE }
knitr::include_graphics(path = "figures/r_package.png", auto_pdf = TRUE)
```

R packages/libraries contain additional functions, data and code for analysing, manipulating and plotting different types of data. Many common packages will be installed as default when you install R. Other more specialised packages, such as the `ggplot2` package, must be installed by the user.

Packages found on The Comprehensive R Archive Network (CRAN) which is R’s central software repository can be installed easily using the following command.

```{r eval=FALSE}
install.packages("package_name")
```

Every time you reload R you will need to load the packages you need if they are not one of the ones installed by default. To do this type:

```{r eval=FALSE}
library("package_name")
```

I generally have a list of `library()` functions at the top of my R scripts (`.R` files) for all the packages I use in the script.

Throughout this course you will get a lot of practice installing and loading various packages.

`r hide("R package or R Library?")`
R packages are a collection of R functions, data, and compiled code. You can install these into a directory on your computer.

An R library is a directory containing a R package.

Because of this, the terms R package and R library may be used synonymously. We will use the term package in this workshop.
`r unhide()`

As we will be using a lot of packages we shall use a double colons to specify which package each function belongs to, unless the function is from base R. For example if we use the function `summarize_phyloseq()` from the package `microbiome` we would type the function like below:

__Note__: Do not run the below command.

```{r eval=FALSE}
microbiome::summarize_phyloseq()
```

This convention has 2 benefits:

- We can easily tell which R package each function comes from.
  - This is useful for your future coding where you may copy some, but not all, commands from one script to another. You will therefore know which packages you will need to load.
  - If you need some more documentation about a function you will know what package to look up.
  - Writing your methods will be a lot easier.
- Different packages may have functions with the same name. Specifying the package will ensure you are using the correct function.

## The grammar of graphics
```{r, fig.align = 'center',out.width= '20%', echo=FALSE }
knitr::include_graphics(path = "figures/ggplot2.png", auto_pdf = TRUE)
``` 

During this course we will be using the grammar of graphics coding approach. This approach is implemented by the R package `ggplot2` to create visualisations such as bar charts, box plots, ordination plots etc. In turn `ggplot2` is used by a host of other packages, some of which we will be using. Although `ggplot2` is R code its structure is very different and it takes effort to learn. Thankfully, `ggplot2` is very powerful and flexible, and it produces very professional and clean plots.

We will use the `iris` dataset (inbuilt into R) to show an example of `ggplot2` code and its visualisation output is:

__Note__: If you would like to see the contents of the `iris` dataset you can run the command `View(iris)` in your R instance.

```{r}
#Load library
library(ggplot2)

#Create new ggplot2 object using iris dataset
ggplot2::ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, colour=Species)) +
  #Make the object a scatter plot 
  ggplot2::geom_point() +
  ggplot2::ggtitle("Iris Sepal length vs width") +
  #Set x and y axis label names
  ggplot2::labs(x = "Sepal length", y = "Sepal width")
```

We will not learn `ggplot2` specifically during this course. However, the structure of creating an object will be used. In the above case the initial object was built with `ggplot`. Subsequently additions and edits were carried out with `+` and various other functions.

An important concept of the grammar of graphics is aesthetics. Aesthetics are the parts of a graphic/plot. In the above command we set the aesthetics with the function `aes()` within the `ggplot()` function. The X aesthetic (i.e. what values are assigned to the x axis) was set as the Sepal length values from the column `Sepal.Length` of the dataframe `iris`. In turn the Y axis values are set to the Sepal width and the colouring of the points are set to the Species.

That was a quick introduction to the grammar of graphics. We will be using this to create visualisations with a `phyloseq` object using various R packages specifically designed for community abundance data within `phyloseq` objects.

For more resources on `ggplot2` please see the [appendix](#ggplot2_appendix) of this book.

## phyloseq
```{r, fig.align = 'center',out.width= '20%', echo=FALSE }
knitr::include_graphics(path = "figures/phyloseq_logo.png", auto_pdf = TRUE)
``` 

In this book we will be working with `phyloseq` objects to preprocess  our dataset, create visualisations, and carry out statistical analyses. This is a very popular object type for community abundance datasets as it contains the abundance table, metadata, and taxonomy table in one object, optionally containing the phylogenetic tree and reference sequences if wanted/required.

```{r, fig.align = 'center',out.width= '80%', echo=FALSE }
knitr::include_graphics(path = "figures/phyloseq_input.png", auto_pdf = TRUE)
``` 

<!--chapter:end:03-R_packages.Rmd-->

```{r include=FALSE, cache=FALSE}
suppressPackageStartupMessages({
  library(webexercises)
})

knitr::knit_hooks$set(webex.hide = function(before, options, envir) {
  if (before) {
    if (is.character(options$webex.hide)) {
      hide(options$webex.hide)
    } else {
      hide()
    }
  } else {
    unhide()
  }
})
```
# Import
```{r, fig.align = 'center',out.width= '20%', echo=FALSE }
knitr::include_graphics(path = "figures/import.png", auto_pdf = TRUE)
```

Before carrying out any analysis we first need to import our QIIME2 artifacts into a phyloseq object. Thankfully there is an R package called `qiime2R`

## Script

```{r, fig.align = 'center',out.width= '15%', echo=FALSE }
knitr::include_graphics(path = "figures/r_script.png", auto_pdf = TRUE)
```

Prior to any coding, open and save a new script called "01-Import.R". We will be creating a new script for each chapter and numbering them so we can easily see the order of scripts.

## qiime2R

```{r, fig.align = 'center',out.width= '40%', echo=FALSE }
knitr::include_graphics(path = "figures/qiime2r.png", auto_pdf = TRUE)
```

[`qiime2R`](https://github.com/jbisanz/qiime2R) is an R package for importing QIIME2 artifacts into a R phyloseq object. The package contains many different commands. Its function `read_qza()` can read a single artifact at a time.

The best way to import all your QIIME2 artifacts is with the `qza_to_phyloseq()` function. In your "01-Import.R" script, add the following and run the commands.

```{r, eval=FALSE}
#Set you working directory
#This is useful to have at the top of your scripts
#Ensure you set it as your analysis directory
setwd("~/R/R_community_course/freshwater_data_analysis/")

#Load the package/library
library("qiime2R")

#Import data
pseq <- qiime2R::qza_to_phyloseq(
  features = "table-dada2.qza",
  tree = "rooted-tree.qza",
  taxonomy = "taxonomy.sklearn.qza",
  metadata = "media_metadata.txt"
)
```

This command creates a phyloseq object named `pseq`. It contains:

-   The ASV abundance table (`features = "table-dada2.qza"`).
-   The rooted phylogenetic tree (`tree = "rooted-tree.qza"`).
-   The taxonomic classifications of the ASVs (`taxonomy = "taxonomy.sklearn.qza"`).
-   The sample metadata (`metadata = "media_metadata.txt"`)

## Summarise phyloseq
```{r, fig.align = 'center',out.width= '15%', echo=FALSE }
knitr::include_graphics(path = "figures/list_blue.png", auto_pdf = TRUE)
```

Now that we have imported the data we can extract some summary information from it.

First we will use the `microbiome` package with its `summarize_phyloseq()` function.

```{r, eval=FALSE}
#Load microbiome library
library("microbiome")
#Summary of phyloseq object
microbiome::summarize_phyloseq(pseq)
```

This gives us a plethora of information:

-   The top line tells us if the data is compositional (relative abundance).
-   We get the following list of values in a paragraph and via a list.
    -   Min. number of reads: Number of reads in the sample with the lowest number of reads.
    -   Max. number of reads: Number of reads in the sample with the largest number of reads.
    -   Total number of reads: Sum of all reads across all samples.
    -   Average number of reads: Sum of all reads / number of samples.
    -   Median number of reads: Midpoint read abundance across samples.
    -   Sparsity: See expandable box further down.
    -   Any OTU sum to 1 or less?: States if there are any ASVs with a summed abundance of 1 or less across all the samples. 
    -   Number of singletons: Number of ASVs with a sum of 1 or less across all samples.
    -   Percent of OTUs that are singletons: Percentage of ASVs that only contain one read across all the samples.
    -   Number of sample variables are: Number of sample variables/groupings in our metadata.
    -   The last line shows the names of the sample variables/groupings in our metadata.

`r hide("Sparsity")`
Sparsity is a measure of the number of 0s in a table. It can be represented by the following equation:

$$
sparsity = Z/C
$$

Where:

-   Z = The number of cells that equal zero.
-   C = The total number of cells.

Let's look at an example of an abundance table with a small amount of ASVs and Samples.

|      | Sample1 | Sample2 | Sample3 |
|------|---------|---------|---------|
| ASV1 | 0       | 10      | 24      |
| ASV2 | 1       | 0       | 37      |
| ASV3 | 6       | 25      | 0       |
| ASV4 | 51      | 2       | 0       |

- This abundance table has 12 cells, 3 samples \* 4 ASVs. 
- Of these cells, 4 have an abundance of zero. 
- 4/12 = 0.3333, therefore its sparsity is 0.3333.

Sparsity can be any value from 0-1. The higher the value the more sparse it is, with a value of 1 meaning all the cells have an abundance of zero. The lower the value the less sparse it is, with a value of 0 meaning all the cells have an abundance of 1 or more.

16S data is known to be sparse so high sparsity is not unexpected. Keep in mind that lower levels of taxa (ASVs, Species, & Genera) will generally have more sparse tables that higher levels of taxa (Kingdom, Phylum, Class).
`r unhide()`

If you would like to see how the function calculates its values you can highlight the function on the script editor and press "F2".

## Save the phyloseq object
```{r, fig.align = 'center',out.width= '15%', echo=FALSE }
knitr::include_graphics(path = "figures/r_save.png", auto_pdf = TRUE)
```

When using multiple scripts for analysis it is useful to save the R objects that will be used in different script. This can be carried out with the function `save()`.

```{r, eval=FALSE}
save(pseq, file = "phyloseq.RData")
```

This saves our object `pseq` into the file `phyloseq.RData`. The suffix `R.Data` is the normal convention.

Since our final object is saved we no longer need the objects in the environment. Therefore, you can use the sweep button in the Environment pane to remove them.

```{r, fig.align = 'center',out.width= '40%', echo=FALSE }
knitr::include_graphics(path = "figures/RStudio_env_sweep.png", auto_pdf = TRUE)
```

## Recap

```{r, fig.align = 'center',out.width= '15%', echo=FALSE }
knitr::include_graphics(path = "figures/recap.png", auto_pdf = TRUE)
```

We have imported our QIIME2 artifacts into one phyloseq object so we can analyse the data in R. This object has been saved into a ".RData" file which we will load in the next chapter.

<!--chapter:end:04-Import.Rmd-->

```{r include=FALSE, cache=FALSE}
suppressPackageStartupMessages({
  library(webexercises)
})

knitr::knit_hooks$set(webex.hide = function(before, options, envir) {
  if (before) {
    if (is.character(options$webex.hide)) {
      hide(options$webex.hide)
    } else {
      hide()
    }
  } else {
    unhide()
  }
})
```
# Transformations and preprocessing
```{r, fig.align = 'center',out.width= '20%', echo=FALSE }
knitr::include_graphics(path = "figures/transform.png", auto_pdf = TRUE)
```

In this chapter we will learn how to transform our abundance phyloseq table into a relative/compositional abundance phyloseq and a rarefied phyloseq object.

## Script setup
```{r, fig.align = 'center',out.width= '15%', echo=FALSE }
knitr::include_graphics(path = "figures/setup_2.png", auto_pdf = TRUE)
```

Before starting analysis create and save a new script called "02-Preprocess.R" into your analysis directory.

It is useful to add a title to the top of scripts. Add the below to your script:

```{r, eval=FALSE}
#Preprocessing data
```

Below this add a code section title for our script set-up.

```{r, eval=FALSE}
#Set-up ####
```

Next add your command to set the working directory. Below is an example:

```{r, eval=FALSE}
#Set working directory
setwd("~/R/R_community_course/freshwater_data_analysis/")
```

Additionally, I like to load all the libraries to be used in the script in this section. We will explain their uses later in this chapter.

Add the below to your script:

```{r, eval=FALSE}
#Libraries
library("phyloseq")
library("microbiome")
library("vegan")
```

Our last bit of set-up is to load in our abundance phyloseq object we created in the previous chapter.

```{r, eval=FALSE}
#Load the phyloseq object
load("phyloseq.RData")
```


#Number of reads per sample
reads_sample <- microbiome::readcount(pseq)
reads_sample

#Can extract ASV table (known as otu table in phyloseq)
phyloseq::otu_table(pseq)

#Each row is an ASV and each column is the samples
#Therefore we can get the number of ASVs in data
#Let's make a new vector with this info so we can easily keep track
num_asvs_vec <- c(nrow(phyloseq::otu_table(pseq)))
#Give the 1st element a relevant name
names(num_asvs_vec)[1] <- "abundance"
#View current vector
num_asvs_vec

#Sample with too few samples?
#In your analysis you may have a sample with too few reads
#All our samples are fine for a tutorial case but let us say we only wanted to
#keep samples with >11k reads
#We could remove samples with the following code
pseq_min11K <- phyloseq::subset_samples(pseq, reads_sample > 11000)
microbiome::summarize_phyloseq(pseq_min11K)
microbiome::readcount(pseq_min11K)

#We won't be using this as we are happy with our sample numbers
#Let us therefore remove this sample subsetted variable
rm(pseq_min11K)

#Relative abundance ####
#Convert abundance table to relative abundance (compositional) table
pseq_relabund <- microbiome::transform(pseq, "compositional")
#Summarise and check sample counts which should each amount to 1
microbiome::summarize_phyloseq(pseq_relabund)
microbiome::readcount(pseq_relabund)

#Check the below logic
#When using total abundance values it is useful to have 0 values, singletons, and doubletons
#This is because some alpha diversity metrics require them
#However it is useful to remove low relative abundance data in relative abundance data
#This is so the rare ASVs do not overly affect certain types of analysis

#first remove ASV with relabund equal to 0
#This can occur if samples were removed which had ASVs 
#not present in the remaining samples
pseq_relabund <-  filter_taxa(pseq_relabund, function(x) sum(x) > 0, TRUE)

#Summarise and check sample counts which should each amount to around 1
microbiome::summarize_phyloseq(pseq_relabund)
microbiome::readcount(pseq_relabund)

#All the total relative abundances still equal 1
#This is expected since no samples were removed
#As this is the case there is no need to check if ASVs were removed

#We will now remove rare ASVs as these are not as useful in relative abundance data
#compared to abundance data
#There are many ways to do this
#A common way, recommended by the phyloseq developer
#Remove ASVs with a mean (across samples) less than 1e-5 (relabund)
pseq_relabund <-  
  phyloseq::filter_taxa(
    pseq_relabund, function(x) mean(x) > 1e-5, TRUE)

#Summarise and check sample counts which should each amount to around 1
microbiome::summarize_phyloseq(pseq_relabund)
microbiome::readcount(pseq_relabund)

#Total relative abundance has decreased by a very small amount
#This is what we are looking for, if too much is being removed >0.05
#you will need to try to be gentler with the filtering
#Such as trying 1e-6 rather than 1e-5

#We should also check how many ASVs have been removed
num_asvs_vec["relabund"] <- nrow(phyloseq::otu_table(pseq_relabund))
num_asvs_vec
num_asvs_vec["abundance"] - num_asvs_vec["relabund"]

#We have lost a good amount of ASVs but these only equate to a very small
#amount relabund. This is fine as we generally use relative abundance
#when looking at the larger picture rather than at closer pictures
#instead we can use a rarefied abundance table to look at the closer picture

#We are now happy with our relative abundance table
#Therefore we can save it for further use
save(pseq_relabund, file = "phyloseq_relabund.RData")

#Rarefy abundance table ####
#i.e. convert abundance numbers so each sample has equal depth

#Before rarefying a table it is good to make a rarefaction curve
#This is to help us choose an appropriate rarefaction threshold

#We will use the very useful package vegan
#Ignore any warning message
vegan::rarecurve(
  x = as.data.frame(t(phyloseq::otu_table(pseq))), step = 50)

#Let us improve this and save it into a file
png(filename = "./rarefaction_plot.png", res = 300,
    units = "mm", height = 200, width = 300)
vegan::rarecurve(
  x = as.data.frame(t(phyloseq::otu_table(pseq))), step = 50,
  ylab="ASVs", lwd=1,label=F)
#Add a vertical line of the smallest sample depth
abline(v = min(reads_sample), col="red")
dev.off()

#With this we can see that the majorty of samples plateau at 
#the minimum sampleing depth
#Therefore we can use this as a rarefaction size
pseq_rarefy <- 
  phyloseq::rarefy_even_depth(
    pseq, sample.size = min(reads_sample), rngseed = 1000)

#Summarise and check sample counts which should each amount to 10433
microbiome::summarize_phyloseq(pseq_rarefy)
microbiome::readcount(pseq_rarefy)

#Check ASVs
num_asvs_vec["rarefied"] <- nrow(phyloseq::otu_table(pseq_rarefy))
num_asvs_vec

#Save phyloseq object
save(pseq_relpseq_rarefyabund, file = "phyloseq_rarefied.RData")

<!--chapter:end:05-Preprocess_data.Rmd-->

```{r include=FALSE, cache=FALSE}
suppressPackageStartupMessages({
  library(webexercises)
})

knitr::knit_hooks$set(webex.hide = function(before, options, envir) {
  if (before) {
    if (is.character(options$webex.hide)) {
      hide(options$webex.hide)
    } else {
      hide()
    }
  } else {
    unhide()
  }
})
```
# Taxonomy

<contents>

<!--chapter:end:06-Taxonomy.Rmd-->

```{r include=FALSE, cache=FALSE}
suppressPackageStartupMessages({
  library(webexercises)
})

knitr::knit_hooks$set(webex.hide = function(before, options, envir) {
  if (before) {
    if (is.character(options$webex.hide)) {
      hide(options$webex.hide)
    } else {
      hide()
    }
  } else {
    unhide()
  }
})
```
# Alpha

<contents>

<!--chapter:end:07-Alpha.Rmd-->

```{r include=FALSE, cache=FALSE}
suppressPackageStartupMessages({
  library(webexercises)
})

knitr::knit_hooks$set(webex.hide = function(before, options, envir) {
  if (before) {
    if (is.character(options$webex.hide)) {
      hide(options$webex.hide)
    } else {
      hide()
    }
  } else {
    unhide()
  }
})
```
# Beta

<contents>

<!--chapter:end:08-Beta.Rmd-->

```{r include=FALSE, cache=FALSE}
suppressPackageStartupMessages({
  library(webexercises)
})

knitr::knit_hooks$set(webex.hide = function(before, options, envir) {
  if (before) {
    if (is.character(options$webex.hide)) {
      hide(options$webex.hide)
    } else {
      hide()
    }
  } else {
    unhide()
  }
})
```
# Differential abundance analysis

<contents>

<!--chapter:end:09-Differential_abundance_analysis.Rmd-->

```{r include=FALSE, cache=FALSE}
suppressPackageStartupMessages({
  library(webexercises)
})

knitr::knit_hooks$set(webex.hide = function(before, options, envir) {
  if (before) {
    if (is.character(options$webex.hide)) {
      hide(options$webex.hide)
    } else {
      hide()
    }
  } else {
    unhide()
  }
})
```
# (APPENDIX) Appendix {-}

# Installing required packages

<Note on opening RStudio as administrator.>

<Instructions on Installing all required packages>



# ggplot2 {#ggplot2_appendix}
```{r, fig.align = 'center',out.width= '20%', echo=FALSE }
knitr::include_graphics(path = "figures/ggplot2.png", auto_pdf = TRUE)
```

Below are some useful resource if you would like to learn ggplot2.

The [R Graphics Cookbook](https://r-graphics.org/) is a good place to start. It contains a section called [Understanding ggplot2](https://r-graphics.org/chapter-ggplot2) in its appendix which is useful for learning some key terminologies and concepts.

`ggplot2` requires its input to be in long format. You will therefore need to know how to [convert your wide data to long data](#http://www.cookbook-r.com/Manipulating_data/Converting_data_between_wide_and_long_format/).

<!--chapter:end:10-Appendix.Rmd-->

