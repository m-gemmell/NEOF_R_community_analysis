[["01-R_community_main_workflow.html", "R community analysis Chapter 1 Introduction", " R community analysis Matthew R. Gemmell 2023-03-07 Chapter 1 Introduction A lot of different analysis and visualisations can be carried out with community data. This includes taxonomy and functional abundance tables from 16S rRNA and Shotgun metagenomics analysis. This workshop will teach you how to use R with the phyloseq R object; a specialised object containing an abundance, taxonomy, and metadata table. The workshop will use a 16S dataset that has been pre-analysed with QIIME2 to create the ASV table, taxonomy table, and phylogenetic tree. Supplementary materials will show how to import Bracken shotgun metagenomic abundance data and generic abundance data frames into a phyloseq object. Sessions will start with a brief presentation followed by self-paced computer practicals guided by an online interactive book. The book will contain theory and practice code. This will be reinforced with multiple choice questions that will recap concepts and aid in interpretation of results. At the end of the course learners will be able to: Import QIIME2 artifacts into a phyloseq object. Summarise the abundance and taxonomy contents of a phyloseq object Preprocess the abundance and taxonomy tables. This will include transforming sample counts, and subsetting samples &amp; taxonomies. Understand the grammar of graphics (ggplot2) used by phyloseq and related packages. Carry out alpha &amp; beta diversity, and biomarker detection with the phyloseq object. Produce and customise publication quality plots. Run statistical analysis and incorporate these values into the plots. Convert static plots into interactive html plots with plotly within R. This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["02-Dataset_and_workflow.html", "Chapter 2 Dataset &amp; workflow 2.1 Dataset 2.2 Workflow", " Chapter 2 Dataset &amp; workflow 2.1 Dataset In this tutorial we will be using 16S metabarcdoing datasets derived from surface water from the Durance River in the south-east of France. Two major comparisons were carried out in combination with each other. 2.1.1 Sites Three different sites were chosen on the Durance River. These three sites were representative of an anthropisation (transformation of land by humans) gradient along a river stream. These sites were: Upper Durance sampling site (UD): Bottom part of the alpine part of the river with little/no anthropisation. Middle Durance sampling site (MD): Upper part of agricultural land dominated by apple and pear production. Lower Durance sampling site (LD): Lower part of agricultural land with intensive production of fruits, cereals, and vegetables. 2.1.2 Culture media Surface water was sampled and different culture media were used to produce bacterial lawns for each site. The media used were: Environmental sample (ENV): No media used, frozen at -20°C will DNA extraction. TSA 10% incubated at 28°C for 2 days. KBC incubated at 28°C for 2 days. CVP incubated at 28°C for 3 days. 2.1.3 Summary &amp; questions Each sample and media combination was produced in replicates of three giving a total of 27 samples (343 = 36). The three replicates were cultured on three different plates with the same media. An ASV table, taxonomy table, and phylogenetic tree were produced with QIIME2 and DADA2. With this data we can ask and investigate the following questions: How does the bacterial communities change across the anthropisation gradient? Is there a difference in the replicates of one site and media combination. I.e. do any of the media produce inconsistent profiles. Is there more difference between the sites or the media used? Do any of the media produce a similar taxonomic profile to the environmental sample? 2.2 Workflow "],["03-R_packages.html", "Chapter 3 R Packages 3.1 R packages/libraries 3.2 The grammar of graphics 3.3 phyloseq", " Chapter 3 R Packages During this workshop we will use various R packages with their own intricacies. Before going into analysis we'll introduce you to some of these important concepts. 3.1 R packages/libraries R packages/libraries contain additional functions, data and code for analysing, manipulating and plotting different types of data. Many common packages will be installed as default when you install R. Other more specialised packages, such as the ggplot2 package, must be installed by the user. Packages found on The Comprehensive R Archive Network (CRAN) which is R’s central software repository can be installed easily using the following command. install.packages(&quot;package_name&quot;) Every time you reload R you will need to load the packages you need if they are not one of the ones installed by default. To do this type: library(&quot;package_name&quot;) I generally have a list of library() functions at the top of my R scripts (.R files) for all the packages I use in the script. Throughout this course you will get a lot of practice installing and loading various packages. R package or R Library? R packages are a collection of R functions, data, and compiled code. You can install these into a directory on your computer. An R library is a directory containing a R package. Because of this, the terms R package and R library may be used synonymously. We will use the term package in this workshop. As we will be using a lot of packages we shall use a double colons to specify which package each function belongs to, unless the function is from base R. For example if we use the function summarize_phyloseq() from the package microbiome we would type the function like below: Note: Do not run the below command. microbiome::summarize_phyloseq() This convention has 2 benefits: We can easily tell which R package each function comes from. This is useful for your future coding where you may copy some, but not all, commands from one script to another. You will therefore know which packages you will need to load. If you need some more documentation about a function you will know what package to look up. Writing your methods will be a lot easier. Different packages may have functions with the same name. Specifying the package will ensure you are using the correct function. 3.2 The grammar of graphics During this course we will be using the grammar of graphics coding approach. This approach is implemented by the R package ggplot2 to create visualisations such as bar charts, box plots, ordination plots etc. In turn ggplot2 is used by a host of other packages, some of which we will be using. Although ggplot2 is R code its structure is very different and it takes effort to learn. Thankfully, ggplot2 is very powerful and flexible, and it produces very professional and clean plots. We will use the iris dataset (inbuilt into R) to show an example of ggplot2 code and its visualisation output is: Note: If you would like to see the contents of the iris dataset you can run the command View(iris) in your R instance. #Load library library(ggplot2) #Create new ggplot2 object using iris dataset ggplot2::ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, colour=Species)) + #Make the object a scatter plot ggplot2::geom_point() + ggplot2::ggtitle(&quot;Iris Sepal length vs width&quot;) + #Set x and y axis label names ggplot2::labs(x = &quot;Sepal length&quot;, y = &quot;Sepal width&quot;) We will not learn ggplot2 specifically during this course. However, the structure of creating an object will be used. In the above case the initial object was built with ggplot. Subsequently additions and edits were carried out with + and various other functions. An important concept of the grammar of graphics is aesthetics. Aesthetics are the parts of a graphic/plot. In the above command we set the aesthetics with the function aes() within the ggplot() function. The X aesthetic (i.e. what values are assigned to the x axis) was set as the Sepal length values from the column Sepal.Length of the dataframe iris. In turn the Y axis values are set to the Sepal width and the colouring of the points are set to the Species. That was a quick introduction to the grammar of graphics. We will be using this to create visualisations with a phyloseq object using various R packages specifically designed for community abundance data within phyloseq objects. For more resources on ggplot2 please see the appendix of this book. 3.3 phyloseq In this book we will be working with phyloseq objects to preprocess our dataset, create visualisations, and carry out statistical analyses. This is a very popular object type for community abundance datasets as it contains the abundance table, metadata, and taxonomy table in one object, optionally containing the phylogenetic tree and reference sequences if wanted/required. "],["04-Setup.html", "Chapter 4 Set-up 4.1 Logon instructions 4.2 Mamba", " Chapter 4 Set-up Prior to any analysis we need to setup our environment in the webVNC. 4.1 Logon instructions For this workshop we will be using Virtual Network Computing (VNC). Connect to the VNC with a browser by using the webVNC link you were sent. You will now be in a logged-in Linux VNC desktop with two terminals. You will see something as below (there may be only one terminal which is fine). If you do not see something similar please ask for assistance. If the VNC is taking up too much/little space of your browser you can use the zoom of your browser to adjust the size. You will most likely need to use your browser's tool bar to accomplish this. Ensure you can see the grey borders. These instructions will not work outside of this workshop. If you would like to install your own Linux OS on your desktop or laptop we would recommend Mint Linux The following link is a guide to install Mint Linux: https://linuxmint-installation-guide.readthedocs.io/en/latest/ 4.2 Mamba This workshop requires a lot of packages. These all can be difficult to install with R. Instead we have used Mamba forge to install R, its packages, and Jupyter-notebook (more info below). To learn more about Mamba-forge and how to create your own environment please see the appendix. To set-up your environment for this workshop please run the following code (you must include the full stop and space at the front of the command). . usercommunity You will have successfully activated the environment if you now see (r_community) at the start of your command prompt. This indicates you are now in the mamba environment called r_community created by the instructor. If you are interested in the use script you can look at its contents. less /usr/local/bin/usercommunity Tip: press q to quit less. "],["05-Jupyter.html", "Chapter 5 Jupyter 5.1 Open Jupyter-notebook 5.2 Create R notebook 5.3 Cells and code 5.4 Create new cells 5.5 Running code 5.6 Saving the file 5.7 Close the notebook", " Chapter 5 Jupyter Jupyter-notebook is a nice browser based method to write, edit, and run code. It was initally created for Python coding, but has since branched out to many other languages, such as R. We are using it in this workshop for a variety of its properties: It is popular and well maintained. It is lightweight. Other heavier weight programs, such as RStudio, would struggle in our HPC due to the graphical and CPU load. It is interactive and displays code output. It allows for easier annotation, editing, and debugging than the command line. It provides a graphical interface for hanging directories and choosing files. Before carrying out any analysis we will go through a quick tutorial of jupyter-notebook. 5.1 Open Jupyter-notebook The first step is to open jupyter-notebook. Run the below command in your (r_community) environment. jupyter-notebook This will open jupyter-notebook in firefox. We won't need to access the linux terminal anymore. Leave it running jupyter-notebook and full screen your firefox so you should see something like below. 5.2 Create R notebook The next step is to create a R notebook. Click on the \"New\" button towards the top right, right of the \"Upload\" button. From the dropdown click \"R\" below \"Python 3 (ipykernel)\". This will open up a new R notebook like below. 5.3 Cells and code Jupyter-notebook uses cells (the gray boxes) to separate code. This is very useful to compartmentalise our code. There will already be one cell. Within the cell, type in the below commands. 1+1 2-3 When pressing enter in cells it will create a new line. To run all commands in a cell press CTRL + enter. Run your current cell and you should see something like below. 5.4 Create new cells You can create new cells by 2 different means. Press the + button on the tool bar (between the floppy disk and scissors ). This will add a cell below your currently selected option. Click on the Insert button and use the dropdown to add a cell above or below your currently selected cell. Tip: Hover over the toolbar icons to display a text based description of its function. With that knowledge add a second cell below the first cell. Add the following code to your second cell but do not run it. num_1 &lt;- 3 num_2 &lt;- 10 Tip: Notice there are green lines around your selected cell. Insert a third cell and add the following code to it. Do not run the code. num_1 * num_2 5.5 Running code Try to run the code in the third cell. There should be an error as we have not created the objects num_1 &amp; num_2. We have only written the code for these objects but not run them. We can run all the code in a notebook starting from the first cell to the last cell. Two methods to run all cells are: Click on the \"Cell\" button. Click \"Run All\" from the drop-down options. You should then see something like the below in your notebook. There is no output printed for cell 2 because we are assigning variables. However, now there is the correct output for Cell 3 as the variables were assigned before the command was run. 5.6 Saving the file As with RStudio and other good coding interfaces we can save our notebook. First we should rename the file. Rename the notebook to \"jupyter_tut\": Click on the name of the notebook, currently called \"Untitled\". This is at the very top of the notebook, right of the Jupyter logo. A pop-up called \"Rename Notebook\" will appear. Change the Name to \"jupyter_tut\". Click \"Rename\". Now we can save the file. Two methods to save are: Click the floppy disk on the toolbar. Click on the \"File\" button. Click \"Save and Checkpoint\" from the dropdown options. 5.7 Close the notebook To close the notebook: Click on \"File\". From the dropdown options click \"Close and Halt\". When you are back in the file explorer page you will not yet set the new file you saved. You will need to refresh the page with the Refresh button towards the top right. "],["06-Import.html", "Chapter 6 Import 6.1 Import notebook 6.2 qiime2R 6.3 Summarise phyloseq 6.4 Save the phyloseq object 6.5 Recap", " Chapter 6 Import Before carrying out any analysis we first need to import our QIIME2 artifacts into a phyloseq object. Thankfully there is an R package called qiime2R 6.1 Import notebook Prior to any coding, we will create a new directory for this workshop and create a new notebook called \"01-Import.ipynb\" in it. We will be creating a new notebook for each chapter and numbering them so we can easily see the order of scripts. First create a new directory. In the notebook file explorer, click the \"New\" button. Select \"Folder\" You will have an \"Untitled Folder\". To rename it: Click on the box left of the name. Press the \"Rename\" button that appeared. Change the name to \"R_community_workshop\". Click \"Rename\". Click on your \"R_community_workshop\" folder to move into it. Next step is to create a new R notebook, rename it to \"01-Import\", and save it. Then we can carry on. 6.2 qiime2R qiime2R is an R package for importing QIIME2 artifacts into a R phyloseq object. The package contains many different commands. Its function read_qza() can read a single artifact at a time. The best way to import all your QIIME2 artifacts is with the qza_to_phyloseq() function. In your \"01-Import.R\" script, add the following and run the commands. Tip: You can tab complete and/or copy and paste file paths within the webVNC. #Cell 1 #Load the package/library library(&quot;qiime2R&quot;) #Import data pseq &lt;- qiime2R::qza_to_phyloseq( features = &quot;/pub14/tea/nsc206/NEOF/R_community/data/table-dada2.qza&quot;, tree = &quot;/pub14/tea/nsc206/NEOF/R_community/data/rooted-tree.qza&quot;, taxonomy = &quot;/pub14/tea/nsc206/NEOF/R_community/data/taxonomy.sklearn.qza&quot;, metadata = &quot;/pub14/tea/nsc206/NEOF/R_community/data/media_metadata.txt&quot; ) This command creates a phyloseq object named pseq. It contains: The ASV abundance table (features = \"table-dada2.qza\"). The rooted phylogenetic tree (tree = \"rooted-tree.qza\"). The taxonomic classifications of the ASVs (taxonomy = \"taxonomy.sklearn.qza\"). The sample metadata (metadata = \"media_metadata.txt\") 6.3 Summarise phyloseq Now that we have imported the data we can extract some summary information from it. First we will use the microbiome package with its summarize_phyloseq() function. Create a new cell and write and run the below in it. #Cell 2 #Load microbiome library library(&quot;microbiome&quot;) #Summary of phyloseq object microbiome::summarize_phyloseq(pseq) This gives us a plethora of information: The top line tells us if the data is compositional (relative abundance). We get the following list of values in a paragraph and via a list. Min. number of reads: Number of reads in the sample with the lowest number of reads. Max. number of reads: Number of reads in the sample with the largest number of reads. Total number of reads: Sum of all reads across all samples. Average number of reads: Sum of all reads / number of samples. Median number of reads: Midpoint read abundance across samples. Sparsity: See expandable box further down. Any OTU sum to 1 or less?: States if there are any ASVs with a summed abundance of 1 or less across all the samples. Number of singletons: Number of ASVs with a sum of 1 or less across all samples. Percent of OTUs that are singletons: Percentage of ASVs that only contain one read across all the samples. Number of sample variables are: Number of sample variables/groupings in our metadata. The last line shows the names of the sample variables/groupings in our metadata. Sparsity Sparsity is a measure of the number of 0s in a table. It can be represented by the following equation: \\[ sparsity = Z/C \\] Where: Z = The number of cells that equal zero. C = The total number of cells. Let's look at an example of an abundance table with a small amount of ASVs and Samples. Sample1 Sample2 Sample3 ASV1 0 10 24 ASV2 1 0 37 ASV3 6 25 0 ASV4 51 2 0 This abundance table has 12 cells, 3 samples * 4 ASVs. Of these cells, 4 have an abundance of zero. 4/12 = 0.3333, therefore its sparsity is 0.3333. Sparsity can be any value from 0-1. The higher the value the more sparse it is, with a value of 1 meaning all the cells have an abundance of zero. The lower the value the less sparse it is, with a value of 0 meaning all the cells have an abundance of 1 or more. 16S data is known to be sparse so high sparsity is not unexpected. Keep in mind that lower levels of taxa (ASVs, Species, &amp; Genera) will generally have more sparse tables that higher levels of taxa (Kingdom, Phylum, Class). If you would like to see how the function calculates its values you can view the source code online. 6.4 Save the phyloseq object When using multiple notebooks/scripts for analysis it is useful to save the R objects that will be used in different notebooks/scripts. This can be carried out with the function save(). Write and run the following code in a third cell. #Cell 3 #Save phyloseq as file save(pseq, file = &quot;phyloseq.RData&quot;) This saves our object pseq into the file phyloseq.RData. The suffix .RData is the normal convention. We have saved our final object of the notebook. Close and halt it. 6.5 Recap We have imported our QIIME2 artifacts into one phyloseq object so we can analyse the data in R. This object has been saved into a \".RData\" file which we will load in the next chapter. "],["07-Preprocess_data.html", "Chapter 7 Transformations and preprocessing 7.1 Script setup", " Chapter 7 Transformations and preprocessing In this chapter we will learn how to transform our abundance phyloseq table into a relative/compositional abundance phyloseq and a rarefied phyloseq object. 7.1 Script setup Before starting analysis create and save a new script called \"02-Preprocess.R\" into your analysis directory. It is useful to add a title to the top of scripts. Add the below to your script: #Preprocessing data Below this add a code section title for our script set-up. #Set-up #### Next add your command to set the working directory. Below is an example: #Set working directory setwd(&quot;~/R/R_community_course/freshwater_data_analysis/&quot;) Additionally, I like to load all the libraries to be used in the script in this section. We will explain their uses later in this chapter. Add the below to your script: #Libraries library(&quot;phyloseq&quot;) library(&quot;microbiome&quot;) library(&quot;vegan&quot;) Our last bit of set-up is to load in our abundance phyloseq object we created in the previous chapter. #Load the phyloseq object load(&quot;phyloseq.RData&quot;) #Number of reads per sample reads_sample &lt;- microbiome::readcount(pseq) reads_sample #Can extract ASV table (known as otu table in phyloseq) phyloseq::otu_table(pseq) #Each row is an ASV and each column is the samples #Therefore we can get the number of ASVs in data #Let's make a new vector with this info so we can easily keep track num_asvs_vec &lt;- c(nrow(phyloseq::otu_table(pseq))) #Give the 1st element a relevant name names(num_asvs_vec)[1] &lt;- \"abundance\" #View current vector num_asvs_vec #Sample with too few samples? #In your analysis you may have a sample with too few reads #All our samples are fine for a tutorial case but let us say we only wanted to #keep samples with &gt;11k reads #We could remove samples with the following code pseq_min11K &lt;- phyloseq::subset_samples(pseq, reads_sample &gt; 11000) microbiome::summarize_phyloseq(pseq_min11K) microbiome::readcount(pseq_min11K) #We won't be using this as we are happy with our sample numbers #Let us therefore remove this sample subsetted variable rm(pseq_min11K) #Relative abundance #### #Convert abundance table to relative abundance (compositional) table pseq_relabund &lt;- microbiome::transform(pseq, \"compositional\") #Summarise and check sample counts which should each amount to 1 microbiome::summarize_phyloseq(pseq_relabund) microbiome::readcount(pseq_relabund) #Check the below logic #When using total abundance values it is useful to have 0 values, singletons, and doubletons #This is because some alpha diversity metrics require them #However it is useful to remove low relative abundance data in relative abundance data #This is so the rare ASVs do not overly affect certain types of analysis #first remove ASV with relabund equal to 0 #This can occur if samples were removed which had ASVs #not present in the remaining samples pseq_relabund &lt;- filter_taxa(pseq_relabund, function(x) sum(x) &gt; 0, TRUE) #Summarise and check sample counts which should each amount to around 1 microbiome::summarize_phyloseq(pseq_relabund) microbiome::readcount(pseq_relabund) #All the total relative abundances still equal 1 #This is expected since no samples were removed #As this is the case there is no need to check if ASVs were removed #We will now remove rare ASVs as these are not as useful in relative abundance data #compared to abundance data #There are many ways to do this #A common way, recommended by the phyloseq developer #Remove ASVs with a mean (across samples) less than 1e-5 (relabund) pseq_relabund &lt;- phyloseq::filter_taxa( pseq_relabund, function(x) mean(x) &gt; 1e-5, TRUE) #Summarise and check sample counts which should each amount to around 1 microbiome::summarize_phyloseq(pseq_relabund) microbiome::readcount(pseq_relabund) #Total relative abundance has decreased by a very small amount #This is what we are looking for, if too much is being removed &gt;0.05 #you will need to try to be gentler with the filtering #Such as trying 1e-6 rather than 1e-5 #We should also check how many ASVs have been removed num_asvs_vec[\"relabund\"] &lt;- nrow(phyloseq::otu_table(pseq_relabund)) num_asvs_vec num_asvs_vec[\"abundance\"] - num_asvs_vec[\"relabund\"] #We have lost a good amount of ASVs but these only equate to a very small #amount relabund. This is fine as we generally use relative abundance #when looking at the larger picture rather than at closer pictures #instead we can use a rarefied abundance table to look at the closer picture #We are now happy with our relative abundance table #Therefore we can save it for further use save(pseq_relabund, file = \"phyloseq_relabund.RData\") #Rarefy abundance table #### #i.e. convert abundance numbers so each sample has equal depth #Before rarefying a table it is good to make a rarefaction curve #This is to help us choose an appropriate rarefaction threshold #We will use the very useful package vegan #Ignore any warning message vegan::rarecurve( x = as.data.frame(t(phyloseq::otu_table(pseq))), step = 50) #Let us improve this and save it into a file png(filename = \"./rarefaction_plot.png\", res = 300, units = \"mm\", height = 200, width = 300) vegan::rarecurve( x = as.data.frame(t(phyloseq::otu_table(pseq))), step = 50, ylab=\"ASVs\", lwd=1,label=F) #Add a vertical line of the smallest sample depth abline(v = min(reads_sample), col=\"red\") dev.off() #With this we can see that the majorty of samples plateau at #the minimum sampleing depth #Therefore we can use this as a rarefaction size pseq_rarefy &lt;- phyloseq::rarefy_even_depth( pseq, sample.size = min(reads_sample), rngseed = 1000) #Summarise and check sample counts which should each amount to 10433 microbiome::summarize_phyloseq(pseq_rarefy) microbiome::readcount(pseq_rarefy) #Check ASVs num_asvs_vec[\"rarefied\"] &lt;- nrow(phyloseq::otu_table(pseq_rarefy)) num_asvs_vec #Save phyloseq object save(pseq_relpseq_rarefyabund, file = \"phyloseq_rarefied.RData\") "],["08-Taxonomy.html", "Chapter 8 Taxonomy", " Chapter 8 Taxonomy "],["09-Alpha.html", "Chapter 9 Alpha", " Chapter 9 Alpha "],["10-Beta.html", "Chapter 10 Beta", " Chapter 10 Beta "],["11-Differential_abundance_analysis.html", "Chapter 11 Differential abundance analysis", " Chapter 11 Differential abundance analysis "],["12-Appendix.html", "A Mamba installation and environment B Jupyter-notebook C ggplot2", " A Mamba installation and environment Mamba github: https://github.com/mamba-org/mamba Mamba installation: https://github.com/conda-forge/miniforge#mambaforge Mamba guide: https://mamba.readthedocs.io/en/latest/user_guide/mamba.html To create the mamba environment r_community run the below commands in your bash. You will need to have installed mamba first. #R community mamba create r_community mamba activate r_community mamba install -c bioconda bioconductor-microbiome mamba install -c r r-tidyverse mamba install -c conda-forge r-devtools #Update r-htmltools as loading devtools doesn’t work in R (from 0.5.2 -&gt; 0.5.4) mamba install -c conda-forge r-htmltools=0.5.4 #If using jupyter-notebook, need to install r kernel for it mamba install -c conda-forge r-irkernel Activate the environment in bash. mamba activate r_community Activate your mamba's R and install Qiime2R. R devtools::install_github(&quot;jbisanz/qiime2R&quot;) B Jupyter-notebook If you are running this on your own computer you can use RStudio. However, you can also use Jupyter-notebook if you are using an HPC or prefer it. If using bash you will need to create an environment with Jupyter-notebook. Ensure you are in the (base) mamba environment. mamba create -n jupyter mamba activate jupyter mamba install -c anaconda jupyter mamba deactivate To run Jupyter-notebook with your r_community environment you can run the following. #Activate you R_community env mamba activate r_community #Run jupyter-notebook (may be a slightly different path) ~/mamba/envs/jupyter/bin/jupyter-notebook C ggplot2 Below are some useful resource if you would like to learn ggplot2. The R Graphics Cookbook is a good place to start. It contains a section called Understanding ggplot2 in its appendix which is useful for learning some key terminologies and concepts. ggplot2 requires its input to be in long format. You will therefore need to know how to convert your wide data to long data. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
